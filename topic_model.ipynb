{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEsZzlG6oZfEHcvpXO8nwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fromakim/2021Election_Analysis/blob/main/topic_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dev Environment"
      ],
      "metadata": {
        "id": "tp4pRUfX_sOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tomotopy\n",
        "!pip install hangul_utils"
      ],
      "metadata": {
        "id": "c0IOURC3AJjF",
        "outputId": "df833c39-e9fe-4345-d651-26bc61d39af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tomotopy in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tomotopy) (1.19.5)\n",
            "Requirement already satisfied: hangul_utils in /usr/local/lib/python3.7/dist-packages (0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "metadata": {
        "id": "nt-d7j6CVZCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "!pip install cmake\n",
        "!mkdir build\n",
        "!cd build && cmake /content/khaiii\n",
        "!cd /content/build/ && make all\n",
        "!cd /content/build/ && make resource\n",
        "!cd /content/build && make install\n",
        "!cd /content/build && make package_python\n",
        "!pip install /content/build/package_python"
      ],
      "metadata": {
        "id": "iCzuF94pVdw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from pykospacing import Spacing\n",
        "from khaiii import KhaiiiApi\n",
        "from hangul_utils import split_syllables, join_jamos"
      ],
      "metadata": {
        "id": "AJM7mXEuU9xk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tomotopy as tp"
      ],
      "metadata": {
        "id": "q22RDph9AGZt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "VSn6jZqK_rUw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "zZDJvi7n_uyF",
        "outputId": "82442c72-1170-457b-96a5-3398e745eec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import Data"
      ],
      "metadata": {
        "id": "JX1LRGHnAh-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/election_sample/tweet.csv')"
      ],
      "metadata": {
        "id": "XNcvuPl6ABH5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text']"
      ],
      "metadata": {
        "id": "68ShVtlDAmUt",
        "outputId": "600e4dcd-7c57-417b-f09e-d4f58fbe76c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       윤석열이랑 이재명이랑 사랑의 도피해서 심상정이 대통령된 다음에 동성혼 법제화 시켜서...\n",
              "1       [속보] 20대 대통령 선거 후보 확정\\n더불어민주당 이재명\\n국민의힘 윤석열\\n정...\n",
              "2       정확히 표현해야 합니다.\\n\\n- 이재명을 안찍는건 당연.\\n- 기권을 하면 이재명...\n",
              "3       이 심상정의 1분을 어떻게 잊을 수 있을까. 나는 절대 못 잊는다. https://...\n",
              "4       심상정을 뽑는 표가 사표가 아니란걸 우리 여성들이 보여줘야 한다. 인구 절반의 여성...\n",
              "                              ...                        \n",
              "5316    윤석열은 끊임없이 까면서\\n이재명에 대해 일언반구도 없는\\n당신도 똑같은 역사의 죄...\n",
              "5317    💚다음주 토요일 서초집회 아젠다💚\\n📌대장동 특검\\n📌합수부 설치\\n📌이재명 구속\\...\n",
              "5318    아니 애초에 이재명이 민주당안밖에서 반문질로 지금까지 커온거 사실인데 무슨 문재인을...\n",
              "5319    여기는 경북울진 주변에 많은 사람들이 공통적으로 하는말 “윤석렬 너무 수준떨어진다”...\n",
              "5320    김종혁 전 국장 \"정진상이 뭔가 고리가 돼 있거나 의심받고 있는데 떡 하니 부실장으...\n",
              "Name: text, Length: 5321, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "oKEUWv3oP8Mb",
        "outputId": "0819b6e1-82d6-4c9a-8bdc-4556253eca14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/stopwords.csv')"
      ],
      "metadata": {
        "id": "zK-qUcoyen4L"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Preprocessing"
      ],
      "metadata": {
        "id": "hgiYglJAb_rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacing = Spacing()\n",
        "api = KhaiiiApi()"
      ],
      "metadata": {
        "id": "NdOWmQv6cNdR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relations = ['JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', 'JC']           # 관계언 (조사)\n",
        "dependents = ['EP', 'EF', 'EC', 'ETN', 'ETM', 'XPN', 'XSN', 'XSV', 'XSA', 'XR']     # 의존격 (어미, 접사)\n",
        "symbols = ['SF', 'SP', 'SS', 'SE', 'SO', 'SL', 'SH', 'SW', 'SWK', 'SN']             # 기호"
      ],
      "metadata": {
        "id": "qX4jT6-RcUCq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unused = []\n",
        "unused.extend(relations)\n",
        "unused.extend(dependents)\n",
        "unused.extend(symbols)"
      ],
      "metadata": {
        "id": "-rSYzl4Ecm2Z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(list_of_lists):\n",
        "    '''\n",
        "    Return flattened list from list of lists.\n",
        "    '''\n",
        "    return [y for x in list_of_lists for y in x]"
      ],
      "metadata": {
        "id": "5Rx8F_w7caZi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def khaiii_analyze(phrase):\n",
        "    '''\n",
        "    Return Lexicons analyzed by Khaiii Analyzer.\n",
        "    '''\n",
        "    return [z.lex for z in flatten([y.morphs for y in api.analyze(phrase)]) if z.tag not in unused]"
      ],
      "metadata": {
        "id": "EHBDdcfzca6e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['original'] = tweets['text']"
      ],
      "metadata": {
        "id": "o_VHV40PchuS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Erase Non-Korean and Non-English Keywords\n",
        "tweets['text'] = tweets['text'].str.replace('[^A-Za-z가-힣0-9ㄱ-ㅎㅏ-ㅣ.,/ ]', ' ')"
      ],
      "metadata": {
        "id": "gwVj6Zbgbm8B"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text'] = tweets['text'].map(split_syllables)"
      ],
      "metadata": {
        "id": "yYwUEjMdcIaZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text'] = tweets['text'].map(join_jamos)"
      ],
      "metadata": {
        "id": "8x9ynFcgcZBN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text'] = tweets['text'].map(lambda x : x.replace(' ', ''))"
      ],
      "metadata": {
        "id": "_CC6FIJMc40b"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text'] = tweets['text'].map(spacing)"
      ],
      "metadata": {
        "id": "juZ5qQCCdAHF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text'] = tweets['text'].map(lambda x : ' '.join(khaiii_analyze(x) if x != '' else ''))"
      ],
      "metadata": {
        "id": "7DFxLaTOdFBd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text']"
      ],
      "metadata": {
        "id": "oDVLfGcqdiDY",
        "outputId": "6c492469-8f39-4076-e9a7-e47e5771bd7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       윤석열 이재명 사랑 도 피하 심상정 대통령 되 다음 동성혼법 제화 서 둘 결혼식 부...\n",
              "1       속보 대 대통령 선거 후보 확정 더불 민주 당이재 명 국민 힘 윤석 열정 당 심상정...\n",
              "2       정확히 표현 하 이재명 안 찍 것 당연 기권 하 이재명 도와주 것 투표 불참 또한 ...\n",
              "3                               이 심상정 분 어떻 잊 수 있 나 절대 못 잊\n",
              "4       심상정 뽑 표 사표 아니 것 우리 여성 보이 주 하 인구 절반 여성 사표 이 협박 ...\n",
              "                              ...                        \n",
              "5316              윤석열 끊임없이 까 이재명 대하 일언반구 없 당신 똑같 역사 죄인 이이\n",
              "5317    다음 주 토요일 서초집회 아젠다대 장 동 특검 합수부 설치 이재명 구속 송영길 탄핵...\n",
              "5318    아니 애초 이재명 민주당 안 반문질 지금 커 오 거 사실 이 무슨 문재인 생각 이재...\n",
              "5319    여기 경북 울진 주변 많 사람 공통 하 말 윤석렬 너무 수준 떨어지 다 반응 내 그...\n",
              "5320    김종혁 전 국장 정진상 뭐 이 고리 되 있 의심 받 있 떡 하 부실장 앉히 것 뭐 ...\n",
              "Name: text, Length: 5321, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('#4: Tokenization ->', df['text'][0])\n",
        "df['text'] = df['text'].apply(lambda x : [y for y in x.split(' ') if y not in stopwords])\n",
        "print('#5: Stopword ->', df['text'][0])\n",
        "\n",
        "# %% In[4]: Train Model\n",
        "\n",
        "model = tp.LDAModel(k = 20, alpha = 0.5)\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if df['text'][i] != []:\n",
        "        model.add_doc(df['text'][i])\n",
        "\n",
        "for i in range(0, 100, 10):\n",
        "    model.train(10)\n",
        "    print(f'Iteration: {i}, Log-Likelihood: {model.ll_per_word}')\n",
        "\n",
        "# %% In[5]: Show Train Results\n",
        "# for k in range(model.k):\n",
        "#     print(f'Top 10 words of topic #{k}')\n",
        "#     print(model.get_topic_words(k, top_n = 10))\n",
        "\n",
        "# %% In[6]: Save Temp Model\n",
        "model.save('./AI/topic_model.bin')\n"
      ],
      "metadata": {
        "id": "nRwO1R3zbMLf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}